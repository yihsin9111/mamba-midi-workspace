{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yihsin/miniforge3/envs/mmpy11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from pl_model import Text_Mmamba_pl\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "# others\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import argparse\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from dataloader import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_torch_model_params(model):\n",
    "    '''\n",
    "    :param model:\n",
    "    :return:\n",
    "    '''\n",
    "    # Find total parameters and trainable parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'total_params': total_params/1000000, 'total_trainable_params': total_trainable_params/1000000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "opt = SimpleNamespace(\n",
    "    device='cuda',\n",
    "    project_name='new_project',\n",
    "    precision='bf16',\n",
    "    root_path='/mnt/gestalt/home/lonian/datasets/Jamendo',\n",
    "    ckpt_save_path='./ckpts',\n",
    "    \n",
    "    model_type='mamba',\n",
    "    layer_num=24,\n",
    "    d_state=512,\n",
    "    is_incontext=False,\n",
    "    \n",
    "    batch=4,\n",
    "    accumulation_step=32,\n",
    "    codec_layer=1,\n",
    "    \n",
    "    is_continue=False,\n",
    "    ckpt=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not opt.is_continue:\n",
    "    ########################################################################\n",
    "    # training\n",
    "    EPOCH = 500\n",
    "    start_epoch = 1\n",
    "    BATCH = opt.batch\n",
    "    project_name = opt.project_name\n",
    "    max_grad_norm = 1\n",
    "    device = opt.device\n",
    "    accumulation_step = opt.accumulation_step\n",
    "    dataset_type = 'Jamendo'\n",
    "    \n",
    "    is_pure_mamba=False\n",
    "    if opt.model_type == 'transformer':\n",
    "        layers = list(range(0, 24))\n",
    "    elif opt.model_type == 'hybrid':\n",
    "        layers = [0, 1, 2, 21, 22, 23]\n",
    "    else:\n",
    "        layers = []\n",
    "        if opt.model_type == 'mamba':\n",
    "            is_pure_mamba=True\n",
    "    \n",
    "    # if opt.is_incontext:\n",
    "    #     condition_methed = 'in_context'\n",
    "    # else:\n",
    "    #     condition_methed = 'cross_attention'\n",
    "    ################################################\n",
    "    config = {}\n",
    "    config['training'] = {\n",
    "        'name': project_name,\n",
    "        'dataset': dataset_type, \n",
    "        'epoch': EPOCH,\n",
    "        # 'data_number': len(metadata),\n",
    "        'batch': BATCH,\n",
    "        'accumulation_step': accumulation_step,\n",
    "        'precision': opt.precision,\n",
    "    }\n",
    "    config['model'] = {\n",
    "        'layers':opt.layer_num,\n",
    "        'vocab_size':1024+1,\n",
    "        'codec_layer': opt.codec_layer,\n",
    "        'd_model':1024,\n",
    "        'drop_p':0.3,\n",
    "        'd_state':opt.d_state,\n",
    "        'num_heads': 8,\n",
    "        'self_atten_layers': layers,\n",
    "        \"is_incontext\": opt.is_incontext,\n",
    "        'is_pure_mamba': is_pure_mamba,\n",
    "    }\n",
    "    config['optimizer'] = {\n",
    "        'optim_lr': 1e-4,\n",
    "        'weight_decay':0.02,\n",
    "        'betas': (0.9, 0.999),\n",
    "    }\n",
    "    \n",
    "    config['scheduler'] = {\n",
    "        'warmup_duration': 100,\n",
    "        'T_max': EPOCH * BATCH // accumulation_step\n",
    "    }\n",
    "    ########################################################################\n",
    "    # ckpts folder path\n",
    "    os.makedirs(opt.ckpt_save_path, exist_ok=True)\n",
    "    ckpt_folder = os.path.join(opt.ckpt_save_path, project_name)\n",
    "    os.makedirs(ckpt_folder, exist_ok=True)\n",
    "    \n",
    "    model = Text_Mmamba_pl(config)\n",
    "    trainer_params = {\n",
    "        \"precision\": config['training']['precision'], #'bf16-mixed',\n",
    "        \"accumulate_grad_batches\": opt.accumulation_step,\n",
    "        \"devices\": 1,\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"max_epochs\": EPOCH,  # 1000\n",
    "        \"log_every_n_steps\": 1,\n",
    "        \"default_root_dir\": ckpt_folder,\n",
    "        'callbacks': [L.pytorch.callbacks.ModelCheckpoint(every_n_train_steps=500, save_top_k=-1)],\n",
    "        # \"callbacks\": [EarlyStopping(monitor=\"training_epoch_mean\", mode=\"min\", divergence_threshold=2.0, check_finite=True, check_on_train_epoch_end=True)]\n",
    "    }\n",
    "    # lightning.pytorch.callbacks.ModelCheckpoint\n",
    "    config['training']['model_size'] = cal_torch_model_params(model)\n",
    "    \n",
    "    with open(os.path.join(ckpt_folder, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    def model_to_dict(model):\n",
    "        model_dict = {}\n",
    "        for name, layer in model.named_children():\n",
    "            model_dict[name] = layer.__class__.__name__  # 紀錄層的類型名稱\n",
    "            # 如果該層有子模塊，遞迴記錄\n",
    "            if list(layer.children()):\n",
    "                model_dict[name] = model_to_dict(layer)\n",
    "        return model_dict\n",
    "    model_structure = model_to_dict(model)\n",
    "    with open(os.path.join(ckpt_folder, 'model_structure.json'), \"w\") as f:\n",
    "        json.dump(model_structure, f, indent=4)\n",
    "        \n",
    "    # train_data = Jamendo_Dataset(root_path = opt.root_path)\n",
    "    # train_loader = DataLoader(dataset=train_data, batch_size = BATCH, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    # trainer = L.Trainer(**trainer_params)\n",
    "    # trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "else:\n",
    "    \n",
    "    config_path = os.path.join(opt.ckpt[::-1].split('/', 4)[-1][::-1], 'config.json')\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    ckpt_folder = os.path.join(opt.ckpt_save_path, config['training']['name'])\n",
    "    os.makedirs(ckpt_folder, exist_ok=True)\n",
    "        \n",
    "    model = Text_Mmamba_pl(config)\n",
    "    trainer_params = {\n",
    "        \"precision\": 'bf16', #config['training']['precision'],\n",
    "        \"accumulate_grad_batches\": opt.accumulation_step,\n",
    "        \"devices\": 1,\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"max_epochs\": config['training']['epoch'],  # 1000\n",
    "        \"log_every_n_steps\": 1,\n",
    "        \"default_root_dir\": ckpt_folder,\n",
    "        'callbacks': [L.pytorch.callbacks.ModelCheckpoint(every_n_train_steps=500, save_top_k=-1)],\n",
    "    }\n",
    "# torch.backends.cuda.enable_flash_sdp(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cuda.enable_flash_sdp(True)\n",
    "train_data = Jamendo_Dataset(root_path = opt.root_path, codec_layer=config['model']['codec_layer'], is_incontext = config['model']['is_incontext'])\n",
    "train_loader = DataLoader(dataset=train_data, batch_size = config['training']['batch'], shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1data shape: (9, 2588) \n",
      "25881 \n",
      "2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1data shape: (9, 2588) 2588\n",
      "\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)data shape: (9, 2588)\n",
      "1\n",
      "1  2588\n",
      "2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588data shape: (9, 2588)data shape: (9, 2588)\n",
      "data shape: (9, 2588)\n",
      "\n",
      "\n",
      "111   258825882588\n",
      "\n",
      "\n",
      "data shape: (9, 2588)data shape: (9, 2588)\n",
      "data shape: (9, 2588)\n",
      "1\n",
      "1 1 25882588 \n",
      "\n",
      "2588\n",
      "data shape: (9, 2588)\n",
      "data shape: (9, 2588)1\n",
      " 12588 \n",
      "data shape: (9, 2588)2588\n",
      "\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 data shape: (9, 2588)2588\n",
      "\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "data shape: (9, 2588)\n",
      "1 2588\n",
      "[tensor([[[1024,  698,  869,  ...,  920,  925,  901]],\n",
      "\n",
      "        [[1024,  568,  698,  ...,   92,  359,  592]],\n",
      "\n",
      "        [[1024,  568,  530,  ...,  770,  710,   39]],\n",
      "\n",
      "        [[1024,  869,  783,  ...,  941,  967,  886]]]), tensor([[ True, False, False,  ..., False, False, False],\n",
      "        [ True, False, False,  ..., False, False, False],\n",
      "        [ True, False, False,  ..., False, False, False],\n",
      "        [ True, False, False,  ..., False, False, False]]), tensor([[[698, 869, 387,  ..., 925, 901, 660]],\n",
      "\n",
      "        [[568, 698, 776,  ..., 359, 592, 698]],\n",
      "\n",
      "        [[568, 530, 229,  ..., 710,  39, 408]],\n",
      "\n",
      "        [[869, 783,   5,  ..., 967, 886, 890]]]), ['This easy listening, electronic lounge track blends calm and quiet elements with a soft and soothing atmosphere. It begins with a sunny day vibe, featuring a filtered drumbeat, tambourine, and a short repeating electric guitar melody, accompanied by a synth pad in the background. The tempo picks up in the second segment, with a groovy drumming rhythm, keyboard accompaniment, percussive bass line, and various percussion hits, creating an upbeat, catchy, and energetic sound. The final segment maintains this energy, with a fast-paced drumming rhythm, keyboard accompaniment, and percussive bass line, adding a joyful and happy feel to the overall piece.', 'This soundtrack track begins with a calming and relaxing ambient segment, featuring mellow wide bells and a wide low synth pad, setting a serene tone. It then transitions into a grim and intense instrumental, characterized by a slow tempo and an unusual, droning harmony of the didgeridoo, evoking a sense of suspense and foreboding. The final segment is a suspenseful and intense piece, with footstep-like percussion, mysterious bell tones, and orchestral accompaniment, culminating in a climactic and haunting atmosphere.', 'This atmospheric, orchestral soundtrack begins with a groovy piano melody, setting the tone for the piece. The melody then transitions into an emotional and passionate arpeggiated electric guitar melody, accompanied by synth pad chords. In the final segment, a solo melody is played over sustained strings, followed by mellow piano chords, maintaining a passionate and emotional atmosphere throughout.', 'This dance, electropop, and pop track is a high-energy party anthem. It begins with a unique didgeridoo intro, transitioning into a happy and upbeat melody played by a flute, accompanied by a driving bass guitar and acoustic drums. The rhythm section takes center stage, with a synth lead playing the main melody and programmed percussion providing a simple yet infectious beat. The bass plays the root notes of the chords, adding depth to the track. The hi-hat adds a touch of flair, and the overall mood is energetic and exciting, making it perfect for a club setting.']]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cuda.enable_flash_sdp(True)\n",
    "train_data = Pop1k7_MIDI_Dataset(root_path = \"/home/yihsin/dataset/pop1k7_cne\", codec_layer=config['model']['codec_layer'], is_incontext = config['model']['is_incontext'])\n",
    "train_loader = DataLoader(dataset=train_data, batch_size = config['training']['batch'], shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/yihsin/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yihsin/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yihsin/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/yihsin/mamba/dataloader.py\", line 107, in __getitem__\n    path = os.path.join(self.root_path, self.pieces[idx])\n                        ^^^^^^^^^^^^^^\nAttributeError: 'Pop1k7_MIDI_Dataset' object has no attribute 'root_path'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1480\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m   1479\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1480\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1505\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1503\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/_utils.py:733\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mAttributeError\u001b[39m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/yihsin/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yihsin/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/yihsin/miniforge3/envs/mmpy11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/yihsin/mamba/dataloader.py\", line 107, in __getitem__\n    path = os.path.join(self.root_path, self.pieces[idx])\n                        ^^^^^^^^^^^^^^\nAttributeError: 'Pop1k7_MIDI_Dataset' object has no attribute 'root_path'\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpy11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
